*-*-*-*-*-*-*-*-*-*-*-* RUNNING STEP 6 *-*-*-*-*-*-*-*-*-*-*-*
**************************************************
(A) Model: (A) Base-DT

--------------------------------------------------

(B) Confusion Matrix:
[[2 1 1]
 [0 4 0]
 [1 1 3]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.67      0.50      0.57         4
           I       0.67      1.00      0.80         4
           M       0.75      0.60      0.67         5

    accuracy                           0.69        13
   macro avg       0.69      0.70      0.68        13
weighted avg       0.70      0.69      0.68        13


--------------------------------------------------

(D) Accuracy: 0.69
Macro-average F1: 0.68
Weighted-average F1: 0.68

--------------------------------------------------

**************************************************
(A) Model: (B) TOP-DT

Parameters:
criterion: ['gini', 'entropy']
max_depth: [3, 5, None]
min_samples_split: [2, 5, 10]

Best Parameters:
criterion: entropy
max_depth: 3
min_samples_split: 5

--------------------------------------------------

(B) Confusion Matrix:
[[3 1 0]
 [0 2 2]
 [1 2 2]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.75      0.75      0.75         4
           I       0.40      0.50      0.44         4
           M       0.50      0.40      0.44         5

    accuracy                           0.54        13
   macro avg       0.55      0.55      0.55        13
weighted avg       0.55      0.54      0.54        13


--------------------------------------------------

(D) Accuracy: 0.54
Macro-average F1: 0.55
Weighted-average F1: 0.54

--------------------------------------------------

**************************************************
(A) Model: (C) Base-MLP

--------------------------------------------------

(B) Confusion Matrix:
[[0 0 4]
 [0 0 4]
 [0 0 5]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00         4
           I       0.00      0.00      0.00         4
           M       0.38      1.00      0.56         5

    accuracy                           0.38        13
   macro avg       0.13      0.33      0.19        13
weighted avg       0.15      0.38      0.21        13


--------------------------------------------------

(D) Accuracy: 0.38
Macro-average F1: 0.19
Weighted-average F1: 0.21

--------------------------------------------------

**************************************************
(A) Model: (D) TOP-MLP

Parameters:
activation: ['logistic', 'tanh', 'relu']
hidden_layer_sizes: [(30, 50), (10, 10, 10)]
solver: ['adam', 'sgd']

Best Parameters:
activation: tanh
hidden_layer_sizes: (10, 10, 10)
solver: adam

--------------------------------------------------

(B) Confusion Matrix:
[[2 0 2]
 [0 4 0]
 [1 1 3]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.67      0.50      0.57         4
           I       0.80      1.00      0.89         4
           M       0.60      0.60      0.60         5

    accuracy                           0.69        13
   macro avg       0.69      0.70      0.69        13
weighted avg       0.68      0.69      0.68        13


--------------------------------------------------

(D) Accuracy: 0.69
Macro-average F1: 0.69
Weighted-average F1: 0.68

--------------------------------------------------

**************************************************
(A) Model: (A) Base-DT

--------------------------------------------------

(B) Confusion Matrix:
[[2 0 2]
 [1 2 1]
 [1 2 2]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.50      0.50      0.50         4
           I       0.50      0.50      0.50         4
           M       0.40      0.40      0.40         5

    accuracy                           0.46        13
   macro avg       0.47      0.47      0.47        13
weighted avg       0.46      0.46      0.46        13


--------------------------------------------------

(D) Accuracy: 0.46
Macro-average F1: 0.47
Weighted-average F1: 0.46

--------------------------------------------------

**************************************************
(A) Model: (B) TOP-DT

Parameters:
criterion: ['gini', 'entropy']
max_depth: [3, 5, None]
min_samples_split: [2, 5, 10]

Best Parameters:
criterion: entropy
max_depth: None
min_samples_split: 2

--------------------------------------------------

(B) Confusion Matrix:
[[3 0 1]
 [0 2 2]
 [0 2 3]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       1.00      0.75      0.86         4
           I       0.50      0.50      0.50         4
           M       0.50      0.60      0.55         5

    accuracy                           0.62        13
   macro avg       0.67      0.62      0.63        13
weighted avg       0.65      0.62      0.63        13


--------------------------------------------------

(D) Accuracy: 0.62
Macro-average F1: 0.63
Weighted-average F1: 0.63

--------------------------------------------------

**************************************************
(A) Model: (C) Base-MLP

--------------------------------------------------

(B) Confusion Matrix:
[[0 0 4]
 [0 0 4]
 [0 0 5]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00         4
           I       0.00      0.00      0.00         4
           M       0.38      1.00      0.56         5

    accuracy                           0.38        13
   macro avg       0.13      0.33      0.19        13
weighted avg       0.15      0.38      0.21        13


--------------------------------------------------

(D) Accuracy: 0.38
Macro-average F1: 0.19
Weighted-average F1: 0.21

--------------------------------------------------

**************************************************
(A) Model: (D) TOP-MLP

Parameters:
activation: ['logistic', 'tanh', 'relu']
hidden_layer_sizes: [(30, 50), (10, 10, 10)]
solver: ['adam', 'sgd']

Best Parameters:
activation: relu
hidden_layer_sizes: (10, 10, 10)
solver: adam

--------------------------------------------------

(B) Confusion Matrix:
[[3 1 0]
 [0 4 0]
 [1 4 0]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.75      0.75      0.75         4
           I       0.44      1.00      0.62         4
           M       0.00      0.00      0.00         5

    accuracy                           0.54        13
   macro avg       0.40      0.58      0.46        13
weighted avg       0.37      0.54      0.42        13


--------------------------------------------------

(D) Accuracy: 0.54
Macro-average F1: 0.46
Weighted-average F1: 0.42

--------------------------------------------------

**************************************************
(A) Model: (A) Base-DT

--------------------------------------------------

(B) Confusion Matrix:
[[2 1 1]
 [0 4 0]
 [1 0 4]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.67      0.50      0.57         4
           I       0.80      1.00      0.89         4
           M       0.80      0.80      0.80         5

    accuracy                           0.77        13
   macro avg       0.76      0.77      0.75        13
weighted avg       0.76      0.77      0.76        13


--------------------------------------------------

(D) Accuracy: 0.77
Macro-average F1: 0.75
Weighted-average F1: 0.76

--------------------------------------------------

**************************************************
(A) Model: (B) TOP-DT

Parameters:
criterion: ['gini', 'entropy']
max_depth: [3, 5, None]
min_samples_split: [2, 5, 10]

Best Parameters:
criterion: entropy
max_depth: 5
min_samples_split: 10

--------------------------------------------------

(B) Confusion Matrix:
[[3 1 0]
 [0 2 2]
 [1 2 2]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.75      0.75      0.75         4
           I       0.40      0.50      0.44         4
           M       0.50      0.40      0.44         5

    accuracy                           0.54        13
   macro avg       0.55      0.55      0.55        13
weighted avg       0.55      0.54      0.54        13


--------------------------------------------------

(D) Accuracy: 0.54
Macro-average F1: 0.55
Weighted-average F1: 0.54

--------------------------------------------------

**************************************************
(A) Model: (C) Base-MLP

--------------------------------------------------

(B) Confusion Matrix:
[[0 4 0]
 [0 4 0]
 [0 5 0]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00         4
           I       0.31      1.00      0.47         4
           M       0.00      0.00      0.00         5

    accuracy                           0.31        13
   macro avg       0.10      0.33      0.16        13
weighted avg       0.09      0.31      0.14        13


--------------------------------------------------

(D) Accuracy: 0.31
Macro-average F1: 0.16
Weighted-average F1: 0.14

--------------------------------------------------

**************************************************
(A) Model: (D) TOP-MLP

Parameters:
activation: ['logistic', 'tanh', 'relu']
hidden_layer_sizes: [(30, 50), (10, 10, 10)]
solver: ['adam', 'sgd']

Best Parameters:
activation: relu
hidden_layer_sizes: (30, 50)
solver: sgd

--------------------------------------------------

(B) Confusion Matrix:
[[2 0 2]
 [0 0 4]
 [2 0 3]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.50      0.50      0.50         4
           I       0.00      0.00      0.00         4
           M       0.33      0.60      0.43         5

    accuracy                           0.38        13
   macro avg       0.28      0.37      0.31        13
weighted avg       0.28      0.38      0.32        13


--------------------------------------------------

(D) Accuracy: 0.38
Macro-average F1: 0.31
Weighted-average F1: 0.32

--------------------------------------------------

**************************************************
(A) Model: (A) Base-DT

--------------------------------------------------

(B) Confusion Matrix:
[[2 1 1]
 [0 3 1]
 [1 1 3]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.67      0.50      0.57         4
           I       0.60      0.75      0.67         4
           M       0.60      0.60      0.60         5

    accuracy                           0.62        13
   macro avg       0.62      0.62      0.61        13
weighted avg       0.62      0.62      0.61        13


--------------------------------------------------

(D) Accuracy: 0.62
Macro-average F1: 0.61
Weighted-average F1: 0.61

--------------------------------------------------

**************************************************
(A) Model: (B) TOP-DT

Parameters:
criterion: ['gini', 'entropy']
max_depth: [3, 5, None]
min_samples_split: [2, 5, 10]

Best Parameters:
criterion: entropy
max_depth: 5
min_samples_split: 5

--------------------------------------------------

(B) Confusion Matrix:
[[3 0 1]
 [0 2 2]
 [1 0 4]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.75      0.75      0.75         4
           I       1.00      0.50      0.67         4
           M       0.57      0.80      0.67         5

    accuracy                           0.69        13
   macro avg       0.77      0.68      0.69        13
weighted avg       0.76      0.69      0.69        13


--------------------------------------------------

(D) Accuracy: 0.69
Macro-average F1: 0.69
Weighted-average F1: 0.69

--------------------------------------------------

**************************************************
(A) Model: (C) Base-MLP

--------------------------------------------------

(B) Confusion Matrix:
[[0 4 0]
 [0 4 0]
 [0 5 0]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00         4
           I       0.31      1.00      0.47         4
           M       0.00      0.00      0.00         5

    accuracy                           0.31        13
   macro avg       0.10      0.33      0.16        13
weighted avg       0.09      0.31      0.14        13


--------------------------------------------------

(D) Accuracy: 0.31
Macro-average F1: 0.16
Weighted-average F1: 0.14

--------------------------------------------------

**************************************************
(A) Model: (D) TOP-MLP

Parameters:
activation: ['logistic', 'tanh', 'relu']
hidden_layer_sizes: [(30, 50), (10, 10, 10)]
solver: ['adam', 'sgd']

Best Parameters:
activation: tanh
hidden_layer_sizes: (30, 50)
solver: adam

--------------------------------------------------

(B) Confusion Matrix:
[[2 2 0]
 [0 4 0]
 [2 3 0]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.50      0.50      0.50         4
           I       0.44      1.00      0.62         4
           M       0.00      0.00      0.00         5

    accuracy                           0.46        13
   macro avg       0.31      0.50      0.37        13
weighted avg       0.29      0.46      0.34        13


--------------------------------------------------

(D) Accuracy: 0.46
Macro-average F1: 0.37
Weighted-average F1: 0.34

--------------------------------------------------

**************************************************
(A) Model: (A) Base-DT

--------------------------------------------------

(B) Confusion Matrix:
[[3 1 0]
 [1 3 0]
 [0 0 5]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.75      0.75      0.75         4
           I       0.75      0.75      0.75         4
           M       1.00      1.00      1.00         5

    accuracy                           0.85        13
   macro avg       0.83      0.83      0.83        13
weighted avg       0.85      0.85      0.85        13


--------------------------------------------------

(D) Accuracy: 0.85
Macro-average F1: 0.83
Weighted-average F1: 0.85

--------------------------------------------------

**************************************************
(A) Model: (B) TOP-DT

Parameters:
criterion: ['gini', 'entropy']
max_depth: [3, 5, None]
min_samples_split: [2, 5, 10]

Best Parameters:
criterion: entropy
max_depth: 5
min_samples_split: 5

--------------------------------------------------

(B) Confusion Matrix:
[[3 0 1]
 [0 2 2]
 [1 0 4]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.75      0.75      0.75         4
           I       1.00      0.50      0.67         4
           M       0.57      0.80      0.67         5

    accuracy                           0.69        13
   macro avg       0.77      0.68      0.69        13
weighted avg       0.76      0.69      0.69        13


--------------------------------------------------

(D) Accuracy: 0.69
Macro-average F1: 0.69
Weighted-average F1: 0.69

--------------------------------------------------

**************************************************
(A) Model: (C) Base-MLP

--------------------------------------------------

(B) Confusion Matrix:
[[0 4 0]
 [0 4 0]
 [0 5 0]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00         4
           I       0.31      1.00      0.47         4
           M       0.00      0.00      0.00         5

    accuracy                           0.31        13
   macro avg       0.10      0.33      0.16        13
weighted avg       0.09      0.31      0.14        13


--------------------------------------------------

(D) Accuracy: 0.31
Macro-average F1: 0.16
Weighted-average F1: 0.14

--------------------------------------------------

**************************************************
(A) Model: (D) TOP-MLP

Parameters:
activation: ['logistic', 'tanh', 'relu']
hidden_layer_sizes: [(30, 50), (10, 10, 10)]
solver: ['adam', 'sgd']

Best Parameters:
activation: relu
hidden_layer_sizes: (10, 10, 10)
solver: adam

--------------------------------------------------

(B) Confusion Matrix:
[[3 0 1]
 [0 4 0]
 [1 1 3]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.75      0.75      0.75         4
           I       0.80      1.00      0.89         4
           M       0.75      0.60      0.67         5

    accuracy                           0.77        13
   macro avg       0.77      0.78      0.77        13
weighted avg       0.77      0.77      0.76        13


--------------------------------------------------

(D) Accuracy: 0.77
Macro-average F1: 0.77
Weighted-average F1: 0.76

--------------------------------------------------

--------------------------------------------------
The 5 runs for Base DT resulted in
accuracy: [0.69, 0.46, 0.77, 0.62, 0.85]
f1_macro: [0.68, 0.47, 0.75, 0.61, 0.83]
f1_weighted [0.68, 0.46, 0.76, 0.61, 0.85]

Average Accuracy (Base DT): 0.68, Variance: 1.75e-02
Average Macro F1 (Base DT): 0.67, Variance: 1.57e-02
Average Weighted F1 (Base DT): 0.67, Variance: 1.71e-02

--------------------------------------------------
The 5 runs for Top DT resulted in
accuracy: [0.54, 0.62, 0.54, 0.69, 0.69]
f1_macro: [0.55, 0.63, 0.55, 0.69, 0.69]
f1_weighted [0.54, 0.63, 0.54, 0.69, 0.69]

Average Accuracy (Top DT): 0.62, Variance: 4.73e-03
Average Macro F1 (Top DT): 0.62, Variance: 4.42e-03
Average Weighted F1 (Top DT): 0.62, Variance: 4.76e-03

--------------------------------------------------

The 5 runs for Base MLP resulted in
accuracy: [0.38, 0.38, 0.31, 0.31, 0.31]
f1_macro: [0.19, 0.19, 0.16, 0.16, 0.16]
f1_weighted [0.21, 0.21, 0.14, 0.14, 0.14]

Average Accuracy (Base MLP): 0.34, Variance: 1.42e-03
Average Macro F1 (Base MLP): 0.17, Variance: 1.93e-04
Average Weighted F1 (Base MLP): 0.17, Variance: 1.14e-03

--------------------------------------------------

The 5 runs for Top MLP resulted in
accuracy: [0.69, 0.54, 0.38, 0.46, 0.77]
f1_macro: [0.69, 0.46, 0.31, 0.37, 0.77]
f1_weighted [0.68, 0.42, 0.32, 0.34, 0.76]

Average Accuracy (Base MLP): 0.57, Variance: 2.04e-02
Average Macro F1 (Base MLP): 0.57, Variance: 2.04e-02
Average Weighted F1 (Base MLP): 0.57, Variance: 2.04e-02

