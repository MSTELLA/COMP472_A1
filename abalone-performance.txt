**************************************************
(A) Model: (A) Base-DT

--------------------------------------------------

(B) Confusion Matrix:
[[142  44 119]
 [ 53 214  86]
 [155  73 159]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.41      0.47      0.43       305
           I       0.65      0.61      0.63       353
           M       0.44      0.41      0.42       387

    accuracy                           0.49      1045
   macro avg       0.50      0.49      0.49      1045
weighted avg       0.50      0.49      0.49      1045


--------------------------------------------------

(D) Accuracy: 0.49
Macro-average F1: 0.49
Weighted-average F1: 0.49

--------------------------------------------------

**************************************************
(A) Model: (B) TOP-DT

Parameters:
criterion: ['gini', 'entropy']
max_depth: [3, 10, None]
min_samples_split: [2, 5, 10]

Best Parameters:
criterion: entropy
max_depth: 3
min_samples_split: 2

--------------------------------------------------

(B) Confusion Matrix:
[[125  30 150]
 [ 34 263  56]
 [123  76 188]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.44      0.41      0.43       305
           I       0.71      0.75      0.73       353
           M       0.48      0.49      0.48       387

    accuracy                           0.55      1045
   macro avg       0.54      0.55      0.55      1045
weighted avg       0.55      0.55      0.55      1045


--------------------------------------------------

(D) Accuracy: 0.55
Macro-average F1: 0.55
Weighted-average F1: 0.55

--------------------------------------------------

**************************************************
(A) Model: (C) Base-MLP

--------------------------------------------------

(B) Confusion Matrix:
[[142  44 119]
 [ 53 214  86]
 [155  73 159]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.41      0.47      0.43       305
           I       0.65      0.61      0.63       353
           M       0.44      0.41      0.42       387

    accuracy                           0.49      1045
   macro avg       0.50      0.49      0.49      1045
weighted avg       0.50      0.49      0.49      1045


--------------------------------------------------

(D) Accuracy: 0.50
Macro-average F1: 0.39
Weighted-average F1: 0.41

--------------------------------------------------

**************************************************
(A) Model: (D) TOP-MLP

Parameters:
activation: ['sigmoid', 'tanh', 'relu']
hidden_layer_sizes: [(25, 50), (10, 10, 10)]
solver: ['adam', 'sgd']

Best Parameters:
activation: tanh
hidden_layer_sizes: (25, 50)
solver: adam

--------------------------------------------------

(B) Confusion Matrix:
[[142  44 119]
 [ 53 214  86]
 [155  73 159]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.41      0.47      0.43       305
           I       0.65      0.61      0.63       353
           M       0.44      0.41      0.42       387

    accuracy                           0.49      1045
   macro avg       0.50      0.49      0.49      1045
weighted avg       0.50      0.49      0.49      1045


--------------------------------------------------

(D) Accuracy: 0.54
Macro-average F1: 0.53
Weighted-average F1: 0.53

--------------------------------------------------

**************************************************
(A) Model: (A) Base-DT

--------------------------------------------------

(B) Confusion Matrix:
[[135  45 133]
 [ 41 203  91]
 [161  63 173]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.40      0.43      0.42       313
           I       0.65      0.61      0.63       335
           M       0.44      0.44      0.44       397

    accuracy                           0.49      1045
   macro avg       0.50      0.49      0.49      1045
weighted avg       0.49      0.49      0.49      1045


--------------------------------------------------

(D) Accuracy: 0.49
Macro-average F1: 0.49
Weighted-average F1: 0.49

--------------------------------------------------

**************************************************
(A) Model: (B) TOP-DT

Parameters:
criterion: ['gini', 'entropy']
max_depth: [3, 10, None]
min_samples_split: [2, 5, 10]

Best Parameters:
criterion: entropy
max_depth: 3
min_samples_split: 2

--------------------------------------------------

(B) Confusion Matrix:
[[178  41  94]
 [ 44 255  36]
 [192  74 131]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.43      0.57      0.49       313
           I       0.69      0.76      0.72       335
           M       0.50      0.33      0.40       397

    accuracy                           0.54      1045
   macro avg       0.54      0.55      0.54      1045
weighted avg       0.54      0.54      0.53      1045


--------------------------------------------------

(D) Accuracy: 0.54
Macro-average F1: 0.54
Weighted-average F1: 0.53

--------------------------------------------------

**************************************************
(A) Model: (C) Base-MLP

--------------------------------------------------

(B) Confusion Matrix:
[[135  45 133]
 [ 41 203  91]
 [161  63 173]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.40      0.43      0.42       313
           I       0.65      0.61      0.63       335
           M       0.44      0.44      0.44       397

    accuracy                           0.49      1045
   macro avg       0.50      0.49      0.49      1045
weighted avg       0.49      0.49      0.49      1045


--------------------------------------------------

(D) Accuracy: 0.54
Macro-average F1: 0.43
Weighted-average F1: 0.45

--------------------------------------------------

**************************************************
(A) Model: (D) TOP-MLP

Parameters:
activation: ['sigmoid', 'tanh', 'relu']
hidden_layer_sizes: [(25, 50), (10, 10, 10)]
solver: ['adam', 'sgd']

Best Parameters:
activation: tanh
hidden_layer_sizes: (10, 10, 10)
solver: adam

--------------------------------------------------

(B) Confusion Matrix:
[[135  45 133]
 [ 41 203  91]
 [161  63 173]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.40      0.43      0.42       313
           I       0.65      0.61      0.63       335
           M       0.44      0.44      0.44       397

    accuracy                           0.49      1045
   macro avg       0.50      0.49      0.49      1045
weighted avg       0.49      0.49      0.49      1045


--------------------------------------------------

(D) Accuracy: 0.54
Macro-average F1: 0.54
Weighted-average F1: 0.54

--------------------------------------------------

**************************************************
(A) Model: (A) Base-DT

--------------------------------------------------

(B) Confusion Matrix:
[[150  46 146]
 [ 41 232  70]
 [131  81 148]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.47      0.44      0.45       342
           I       0.65      0.68      0.66       343
           M       0.41      0.41      0.41       360

    accuracy                           0.51      1045
   macro avg       0.51      0.51      0.51      1045
weighted avg       0.50      0.51      0.51      1045


--------------------------------------------------

(D) Accuracy: 0.51
Macro-average F1: 0.51
Weighted-average F1: 0.51

--------------------------------------------------

**************************************************
(A) Model: (B) TOP-DT

Parameters:
criterion: ['gini', 'entropy']
max_depth: [3, 10, None]
min_samples_split: [2, 5, 10]

Best Parameters:
criterion: gini
max_depth: 3
min_samples_split: 2

--------------------------------------------------

(B) Confusion Matrix:
[[  0  81 261]
 [  0 292  51]
 [  0 103 257]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.00      0.00      0.00       342
           I       0.61      0.85      0.71       343
           M       0.45      0.71      0.55       360

    accuracy                           0.53      1045
   macro avg       0.36      0.52      0.42      1045
weighted avg       0.36      0.53      0.42      1045


--------------------------------------------------

(D) Accuracy: 0.53
Macro-average F1: 0.42
Weighted-average F1: 0.42

--------------------------------------------------

**************************************************
(A) Model: (C) Base-MLP

--------------------------------------------------

(B) Confusion Matrix:
[[150  46 146]
 [ 41 232  70]
 [131  81 148]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.47      0.44      0.45       342
           I       0.65      0.68      0.66       343
           M       0.41      0.41      0.41       360

    accuracy                           0.51      1045
   macro avg       0.51      0.51      0.51      1045
weighted avg       0.50      0.51      0.51      1045


--------------------------------------------------

(D) Accuracy: 0.51
Macro-average F1: 0.42
Weighted-average F1: 0.42

--------------------------------------------------

**************************************************
(A) Model: (D) TOP-MLP

Parameters:
activation: ['sigmoid', 'tanh', 'relu']
hidden_layer_sizes: [(25, 50), (10, 10, 10)]
solver: ['adam', 'sgd']

Best Parameters:
activation: tanh
hidden_layer_sizes: (10, 10, 10)
solver: adam

--------------------------------------------------

(B) Confusion Matrix:
[[150  46 146]
 [ 41 232  70]
 [131  81 148]]

--------------------------------------------------

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.47      0.44      0.45       342
           I       0.65      0.68      0.66       343
           M       0.41      0.41      0.41       360

    accuracy                           0.51      1045
   macro avg       0.51      0.51      0.51      1045
weighted avg       0.50      0.51      0.51      1045


--------------------------------------------------

(D) Accuracy: 0.55
Macro-average F1: 0.53
Weighted-average F1: 0.53

--------------------------------------------------

