--------------------------------------------------
Model: (A) Base-DT

(B) Confusion Matrix:
[[128  69 134]
 [ 52 216  71]
 [151  62 162]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.39      0.39      0.39       331
           I       0.62      0.64      0.63       339
           M       0.44      0.43      0.44       375

    accuracy                           0.48      1045
   macro avg       0.48      0.49      0.48      1045
weighted avg       0.48      0.48      0.48      1045


(D) Accuracy: 0.48
Macro-average F1: 0.48
Weighted-average F1: 0.48
--------------------------------------------------

--------------------------------------------------
Model: (B) TOP-DT

(B) Confusion Matrix:
[[125  50 156]
 [ 33 266  40]
 [118  73 184]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.45      0.38      0.41       331
           I       0.68      0.78      0.73       339
           M       0.48      0.49      0.49       375

    accuracy                           0.55      1045
   macro avg       0.54      0.55      0.54      1045
weighted avg       0.54      0.55      0.54      1045


(D) Accuracy: 0.55
Macro-average F1: 0.54
Weighted-average F1: 0.54
--------------------------------------------------

--------------------------------------------------
Model: (C) Base-MLP

(B) Confusion Matrix:
[[128  69 134]
 [ 52 216  71]
 [151  62 162]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.39      0.39      0.39       331
           I       0.62      0.64      0.63       339
           M       0.44      0.43      0.44       375

    accuracy                           0.48      1045
   macro avg       0.48      0.49      0.48      1045
weighted avg       0.48      0.48      0.48      1045


(D) Accuracy: 0.54
Macro-average F1: 0.43
Weighted-average F1: 0.44
--------------------------------------------------

--------------------------------------------------
Model: (D) TOP-MLP

(B) Confusion Matrix:
[[128  69 134]
 [ 52 216  71]
 [151  62 162]]

(C) Classification Report:
              precision    recall  f1-score   support

           F       0.39      0.39      0.39       331
           I       0.62      0.64      0.63       339
           M       0.44      0.43      0.44       375

    accuracy                           0.48      1045
   macro avg       0.48      0.49      0.48      1045
weighted avg       0.48      0.48      0.48      1045


(D) Accuracy: 0.55
Macro-average F1: 0.54
Weighted-average F1: 0.54
--------------------------------------------------

